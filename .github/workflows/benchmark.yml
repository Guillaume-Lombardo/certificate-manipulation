name: Benchmark

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  large-bundle:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Setup uv
        uses: astral-sh/setup-uv@v5

      - name: Install dependencies
        run: uv sync --group dev

      - name: Run benchmark with thresholds
        run: |
          uv run python scripts/benchmark_large_bundle.py \
            --cert-count 500 \
            --workdir .benchmarks/ci \
            --clean \
            --thresholds-file benchmarks/ci_thresholds.json \
            --output-json .benchmarks/ci/report.json

      - name: Add benchmark summary
        run: |
          uv run python - <<'PY' >> "$GITHUB_STEP_SUMMARY"
          import json
          from pathlib import Path

          report = json.loads(Path(".benchmarks/ci/report.json").read_text(encoding="utf-8"))
          timings = report["timings_seconds"]
          print("## Large Bundle Benchmark")
          print()
          print(f"- cert_count: `{report['cert_count']}`")
          print(f"- combine: `{timings['combine']:.4f}s`")
          print(f"- split: `{timings['split']:.4f}s`")
          print(f"- filter: `{timings['filter']:.4f}s`")
          PY

      - name: Upload benchmark artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-large-bundle
          path: .benchmarks/ci/report.json
